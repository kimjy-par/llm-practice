{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc6dc984-b298-4d3d-8030-a466e26acef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, PreTrainedTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97bb8590-a509-4664-a0da-15968eec3c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dde23ab16c74d179bfcc600381b257d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.83M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f6ad7c9739b46358c767e556621f7bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n",
      "/opt/homebrew/anaconda3/envs/mlops-auth-api/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37b7ffae056648fa92d455387d88fab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/513M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"skt/kogpt2-base-v2\"\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2698edb-0d35-4d18-98dd-1bcf27edf1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"옛날 옛적에\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "022c5732-5f97-4d4b-9edb-e23495a2bf96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[12346, 10256, 16871]]), 'token_type_ids': tensor([[0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02c5a147-57f3-48a9-b28a-cff8f5e809ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(inputs[\"input_ids\"], max_length=50, num_return_sequences=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d65f59a0-eb91-428d-9bc3-abb6c014aa10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12346, 10256, 16871,  9022, 10706,  9194,  8367,  8159, 43940,  8094,\n",
       "         39536,  7501,  7648, 14986,  9416,  6947, 41481,  9194,  8367,  8159,\n",
       "         43940,  8094, 39536,  7501,  7648, 14986,  9554,  9194,  8367,  8159,\n",
       "         43940,  8094, 39536,  7501,  7648, 23358,  8367,  8159, 43940,  8094,\n",
       "         39536,  7501, 19190,  9300,  9401,  9194,  8367,  8159, 43940,  8094]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5509d3af-6ed2-4147-8986-8dbe77604da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c34d289d-2a96-49e0-bb4a-b27308c5cce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"옛날 옛적에 그 유명한 '청자상감운학문매병'이 있었다.\\n그것은 '청자상감운학문매병'이 아니라 '청자상감운학문매병'이다.\\n청자상감운학문매병은 청자의 '청자상감운\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe59ae5-c445-4de5-bd47-0f564941d3f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
